# Configuration file for Xeon X5550 Gainestown
# See http://en.wikipedia.org/wiki/Gainestown_(microprocessor)#Gainestown
# and http://ark.intel.com/products/37106

#include nehalem

[perf_model/core]
frequency = 2.66

[perf_model/l3_cache]
perfect = false
cache_block_size = 64
cache_size = 4096 #FIXME8192
associativity = 16
address_hash = mask
replacement_policy = lru
data_access_time = 30 # 35 cycles total according to membench, +L1+L2 tag times
tags_access_time = 10
perf_model_type = parallel
writethrough = 0
shared_cores = 4

[perf_model/dram_directory]
# total_entries = number of entries per directory controller.
total_entries = 1048576
associativity = 16
directory_type = full_map

[perf_model/dram]
# -1 means that we have a number of distributed DRAM controllers (4 in this case)
num_controllers = -1
controllers_interleaving = 4
# DRAM access latency in nanoseconds. Should not include L1-LLC tag access time, directory access time (14 cycles = 5.2 ns),
# or network time [(cache line size + 2*{overhead=40}) / network bandwidth = 18 ns]
# Membench says 175 cycles @ 2.66 GHz = 66 ns total
latency = 45
#FIXMEper_controller_bandwidth = 7.6              # In GB/s, as measured by core_validation-dram
per_controller_bandwidth = 14.9              # In GB/s
chips_per_dimm = 8
dimms_per_controller = 4

# DRAM CIM
# ELP2IM timing
#DDR3
# for random access
#not = 128 
#and = 177 
#or = 177
#nand = 231
#nor = 231
#xor = 334
#cimread = 21 # row buffer hit delay

# for sequencial access
#not = 128
#and = 124 
#or = 124
#nand = 178
#nor = 178
#xor = 334
#cimread = 21 # row buffer hit delay

#DDR4_8Gb_x8_2400
# for random access
#not = 100 
#and = 146 
#or = 146
#nand = 196
#nor = 196
#xor = 300
#cimread = 17 # row buffer hit delay

# for sequencial access
not = 104

# C = A &(|) B
and = 156 # AAP -> APP -> AAP 
or = 156
# A = A &(|) B
and_s = 100 # APP -> AP  
or_s = 100

nand = 208 #check here
nor = 208 #check here
xor = 312
cimread = 19 # row buffer hit delay

[network]
memory_model_1 = bus
memory_model_2 = bus

[network/bus]
bandwidth = 25.6 # in GB/s. Actually, it's 12.8 GB/s per direction and per connected chip pair
ignore_local_traffic = true # Memory controllers are on-chip, so traffic from core0 to dram0 does not use the QPI links

